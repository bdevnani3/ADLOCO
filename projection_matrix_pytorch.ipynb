{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb736f95",
   "metadata": {},
   "source": [
    "Computing Projection - sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cad6959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16666667, 0.16666667, 0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "\n",
    "images = np.array([[1,1,1], [0,0,0]])\n",
    "\n",
    "text = np.array([[2,2,2], [0,0,0]])\n",
    "\n",
    "proj, _, _, _ = lstsq(text, images)\n",
    "\n",
    "proj\n",
    "# np.dot(text,proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49b484b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import dataloaders as dataloader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from classes import CLASSES, CUSTOM_TEMPLATES, GENERIC_PROMPT_COLLECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0507887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /nethome/bdevnani3/flash1/long_tail_lang/data/ImageNet_LT/ImageNet_LT_train.txt\n",
      "Use data transformation: Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.5, 1), ratio=(0.75, 1.3333), interpolation=bicubic)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=None)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      ")\n",
      "***********************DATASET: train random_prompts\n",
      "************************* dict_keys(['default', 'ImageNet', 'bestImageNet'])\n",
      "train 115846\n",
      "No sampler.\n",
      "Shuffle is True.\n"
     ]
    }
   ],
   "source": [
    "# Load Image Data\n",
    "\n",
    "d = dataloader.load_data(\n",
    "    data_root=\"./datasets/ImageNet/\",\n",
    "    dataset=\"ImageNet_LT\",\n",
    "    phase=\"train\",\n",
    "    batch_size=128,\n",
    "#     batch_size=1,\n",
    "    sampler_dic=None,\n",
    "    num_workers=12,\n",
    "    type=\"random_prompts\",\n",
    "    prompt_set=\"ImageNet\",\n",
    ")\n",
    "data = d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "302be98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from clip import clip\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "# Initialize CLIP models \n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, clip_model):\n",
    "        super().__init__()\n",
    "        self.transformer = clip_model.transformer\n",
    "        self.positional_embedding = clip_model.positional_embedding\n",
    "        self.ln_final = clip_model.ln_final\n",
    "        self.text_projection = clip_model.text_projection\n",
    "        self.dtype = clip_model.dtype\n",
    "        self.token_embedding = clip_model.token_embedding\n",
    "\n",
    "    def forward(self, text):\n",
    "        x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "        x = x + self.positional_embedding.type(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection\n",
    "\n",
    "        return x\n",
    "\n",
    "def load_clip_to_cpu(visual_backbone):\n",
    "    backbone_name = visual_backbone\n",
    "    url = clip._MODELS[backbone_name]\n",
    "    model_path = clip._download(url, os.path.expanduser(\"~/.cache/clip\"))\n",
    "\n",
    "    try:\n",
    "        # loading JIT archive\n",
    "        model = torch.jit.load(model_path, map_location=\"cpu\").eval()\n",
    "        state_dict = None\n",
    "\n",
    "    except RuntimeError:\n",
    "        state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "\n",
    "    model = clip.build_model(state_dict or model.state_dict())\n",
    "\n",
    "    return model\n",
    "\n",
    "clip_model = load_clip_to_cpu(\"RN50\")\n",
    "\n",
    "visual_model = torch.nn.DataParallel(clip_model.visual).cuda()\n",
    "\n",
    "text_model = TextEncoder(clip_model)\n",
    "text_model = torch.nn.DataParallel(text_model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84fc60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4a009742d342fe86deb9cbfe1bf1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/906 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "final_images, final_texts = [], []\n",
    "final_labels = []\n",
    "\n",
    "# count = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for im, label, _, path in tqdm(data):\n",
    "        x = visual_model(im.half()).float()\n",
    "        x = x / x.norm(dim=-1, keepdim=True)\n",
    "        final_images.append(x)\n",
    "\n",
    "        templates = np.array(GENERIC_PROMPT_COLLECTIONS[\"ImageNet\"])[path.cpu()]\n",
    "        classnames_for_labels = np.array(CLASSES)[label.cpu()]\n",
    "\n",
    "        texts = clip.tokenize(t.format(c) for t,c in zip(templates, classnames_for_labels))\n",
    "        texts = texts.cuda()\n",
    "        zeroshot_weights = text_model(texts).float()\n",
    "        zeroshot_weights = zeroshot_weights / zeroshot_weights.norm(\n",
    "            dim=-1, keepdim=True\n",
    "        )\n",
    "        final_texts.append(zeroshot_weights)\n",
    "        final_labels.append(label)\n",
    "#         count[label.item] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce394c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_images = torch.cat(final_images, dim=0)\n",
    "final_texts = torch.cat(final_texts, dim=0)\n",
    "final_labels = torch.cat(final_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93d64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_images, \"clip_embedded_images.pt\")\n",
    "torch.save(final_texts, \"clip_embedded_texts.pt\")\n",
    "torch.save(final_labels, \"clip_embedded_image_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828fcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "final_images = torch.load(\"clip_embedded_images.pt\")\n",
    "final_texts = torch.load(\"clip_embedded_texts.pt\")\n",
    "final_labels = torch.load(\"clip_embedded_image_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87075e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([115846, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6573de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj, _, _, _ = lstsq(final_texts.cpu(), final_images.cpu())\n",
    "proj.shape\n",
    "np.save(\"imagenet_text2img_proj.npy\", proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c4eb0",
   "metadata": {},
   "source": [
    "Balanced projection matrix - 1 instance per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36db2247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3909fad6e54056aed58030b49c1155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balanced_images = np.zeros((1000, 1024))\n",
    "balanced_texts = np.zeros((1000, 1024))\n",
    "\n",
    "for i, label in tqdm(enumerate(final_labels)):\n",
    "    balanced_images[label,:] = final_images[i,:].cpu()\n",
    "    balanced_texts[label,:] = final_texts[i,:].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7cc62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_proj, _, _, _ = lstsq(balanced_texts, balanced_images)\n",
    "balanced_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a092a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"imagenet_text2img_balanced_proj.npy\", balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a60eb",
   "metadata": {},
   "source": [
    "Balanced projection matrix - 100 instances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a09223",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_frequencies = {}\n",
    "for label in final_labels:\n",
    "    if label.item() not in label_frequencies:\n",
    "        label_frequencies[label.item()] = 0\n",
    "    label_frequencies[label.item()] += 1\n",
    "\n",
    "indices_by_label = {}\n",
    "\n",
    "for i, label in enumerate(final_labels):\n",
    "    if label.item() not in indices_by_label:\n",
    "        indices_by_label[label.item()] = []\n",
    "    indices_by_label[label.item()].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee7a4609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d0b7c367db4feab1bcc2f20b491ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "upsampled_images = np.zeros((100000, 1024))\n",
    "upsampled_texts = np.zeros((100000, 1024))\n",
    "\n",
    "for i in tqdm(range(100000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled_images[i] = final_images[idx].cpu()\n",
    "    upsampled_texts[i] = final_texts[idx].cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29984ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled_balanced_proj, _, _, _ = lstsq(upsampled_texts, upsampled_images)\n",
    "# upsampled_balanced_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71100bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"imagenet_text2img_upsampled_balanced_proj.npy\", upsampled_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a61905c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af996931984c4e75a7a73b97187f3479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "upsampled_images = np.zeros((400000, 1024))\n",
    "upsampled_texts = np.zeros((400000, 1024))\n",
    "\n",
    "for i in tqdm(range(400000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled_images[i] = final_images[idx].cpu()\n",
    "    upsampled_texts[i] = final_texts[idx].cpu()\n",
    "\n",
    "# upsampled_balanced_proj, _, _, _ = lstsq(upsampled_texts, upsampled_images)\n",
    "# upsampled_balanced_proj.shape\n",
    "\n",
    "# np.save(\"imagenet_text2img_upsampled_balanced_proj400.npy\", upsampled_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498010f3",
   "metadata": {},
   "source": [
    "Balanced projection matrix - 100 instances/pooling of labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d457a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e229983b7ca242a78f4d8330906f388a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_labels_text = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for label in tqdm(range(1000)):\n",
    "        all_labels_text[label] = []\n",
    "\n",
    "        templates = np.array(GENERIC_PROMPT_COLLECTIONS[\"ImageNet\"])\n",
    "        c = np.array(CLASSES)[label]\n",
    "            \n",
    "        texts = clip.tokenize([template.format(c) for template in templates]) \n",
    "        texts = texts.cuda()\n",
    "        zeroshot_weights = text_model(texts).float()\n",
    "        zeroshot_weights = zeroshot_weights / zeroshot_weights.norm(\n",
    "            dim=-1, keepdim=True\n",
    "        )\n",
    "        all_labels_text[label].append(zeroshot_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "upsampled2_images = np.zeros((100000, 1024))\n",
    "upsampled2_texts = np.zeros((100000, 1024))\n",
    "\n",
    "for i in tqdm(range(100000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled2_images[i] = final_images[idx].cpu()\n",
    "    idx_2 = random.choice(range(82))\n",
    "    upsampled2_texts[i] = all_labels_text[label][0][idx_2].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ffbeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled2_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c47b7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsampled2_balanced_proj, _, _, _ = lstsq(upsampled2_texts, upsampled2_images)\n",
    "# upsampled2_balanced_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"imagenet_text2img_upsampled2_balanced_proj.npy\", upsampled2_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "upsampled2_images = np.zeros((200000, 1024))\n",
    "upsampled2_texts = np.zeros((200000, 1024))\n",
    "\n",
    "for i in tqdm(range(200000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled2_images[i] = final_images[idx].cpu()\n",
    "    idx_2 = random.choice(range(82))\n",
    "    upsampled2_texts[i] = all_labels_text[label][0][idx_2].cpu()\n",
    "    \n",
    "# upsampled2_balanced_proj, _, _, _ = lstsq(upsampled2_texts, upsampled2_images)\n",
    "\n",
    "# np.save(\"imagenet_text2img_upsampled2_balanced_proj200.npy\", upsampled2_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "upsampled2_images = np.zeros((400000, 1024))\n",
    "upsampled2_texts = np.zeros((400000, 1024))\n",
    "\n",
    "for i in tqdm(range(400000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled2_images[i] = final_images[idx].cpu()\n",
    "    idx_2 = random.choice(range(82))\n",
    "    upsampled2_texts[i] = all_labels_text[label][0][idx_2].cpu()\n",
    "    \n",
    "# upsampled2_balanced_proj, _, _, _ = lstsq(upsampled2_texts, upsampled2_images)\n",
    "\n",
    "# np.save(\"imagenet_text2img_upsampled2_balanced_proj400.npy\", upsampled2_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968dc2c9",
   "metadata": {},
   "source": [
    "Balanced projection matrix - 100 instances/pooling of labels/ VL-LTR text pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a42912",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_path = \"/nethome/bdevnani3/flash1/long_tail_lang/data_loader/imagenet/wiki/desc_{}.txt\"\n",
    "\n",
    "all_labels_wiki_text = {}\n",
    "all_labels_wiki_text_embs = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for label in range(1000):\n",
    "        all_labels_wiki_text[label] = []\n",
    "        label_desc_path = desc_path.format(label)\n",
    "        f = open(label_desc_path)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if \"==\" in line:\n",
    "                continue\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            all_labels_wiki_text[label].append(line[:76])\n",
    "        texts = clip.tokenize(all_labels_wiki_text[label])\n",
    "        texts = texts.cuda()\n",
    "        zeroshot_weights = text_model(texts).float()\n",
    "        zeroshot_weights = zeroshot_weights / zeroshot_weights.norm(\n",
    "            dim=-1, keepdim=True\n",
    "        )\n",
    "        all_labels_wiki_text_embs[label] = zeroshot_weights\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "upsampled3_images = np.zeros((100000, 1024))\n",
    "upsampled3_texts = np.zeros((100000, 1024))\n",
    "\n",
    "for i in tqdm(range(100000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled3_images[i] = final_images[idx].cpu()\n",
    "    idx_2 = random.choice(range(len(all_labels_wiki_text[label])))\n",
    "    upsampled3_texts[i] = all_labels_wiki_text_embs[label][idx_2].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled3_balanced_proj, _, _, _ = lstsq(upsampled3_texts, upsampled3_images)\n",
    "# upsampled3_balanced_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cf48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"imagenet_text2img_upsampled3_balanced_proj.npy\", upsampled3_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aaa1a3",
   "metadata": {},
   "source": [
    "Balanced projection matrix - 100 instances/pooling of labels/ VL-LTR text pool + templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e222881",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_wiki_and_template = {}\n",
    "\n",
    "for label in all_labels_wiki_text_embs:\n",
    "    all_labels_wiki_and_template[label] = torch.cat([all_labels_wiki_text_embs[label], all_labels_text[label][0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fc10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "upsampled4_images = np.zeros((100000, 1024))\n",
    "upsampled4_texts = np.zeros((100000, 1024))\n",
    "\n",
    "for i in tqdm(range(100000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled4_images[i] = final_images[idx].cpu()\n",
    "    idx_2 = random.choice(range(len(all_labels_wiki_and_template[label])))\n",
    "    upsampled4_texts[i] = all_labels_wiki_and_template[label][idx_2].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936020b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled4_balanced_proj, _, _, _ = lstsq(upsampled4_texts, upsampled4_images)\n",
    "# upsampled4_balanced_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"imagenet_text2img_upsampled4_balanced_proj.npy\", \n",
    "#         upsampled4_balanced_proj.astype(float))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42431ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "upsampled4_images = np.zeros((400000, 1024))\n",
    "upsampled4_texts = np.zeros((400000, 1024))\n",
    "\n",
    "for i in tqdm(range(400000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled4_images[i] = final_images[idx].cpu()\n",
    "    idx_2 = random.choice(range(len(all_labels_wiki_and_template[label])))\n",
    "    upsampled4_texts[i] = all_labels_wiki_and_template[label][idx_2].cpu()\n",
    "    \n",
    "# upsampled4_balanced_proj, _, _, _ = lstsq(upsampled4_texts, upsampled4_images)\n",
    "# upsampled4_balanced_proj.shape\n",
    "\n",
    "# np.save(\"imagenet_text2img_upsampled4_balanced_proj.npy\", \n",
    "#         upsampled4_balanced_proj.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57419848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "upsampled4_images = np.zeros((800000, 1024))\n",
    "upsampled4_texts = np.zeros((800000, 1024))\n",
    "\n",
    "for i in tqdm(range(800000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx = random.choice(indices_by_label[label])\n",
    "    upsampled4_images[i] = final_images[idx].cpu()\n",
    "    idx_2 = random.choice(range(len(all_labels_wiki_and_template[label])))\n",
    "    upsampled4_texts[i] = all_labels_wiki_and_template[label][idx_2].cpu()\n",
    "# upsampled4_balanced_proj, _, _, _ = lstsq(upsampled4_texts, upsampled4_images)\n",
    "# upsampled4_balanced_proj.shape\n",
    "\n",
    "# np.save(\"imagenet_text2img_upsampled4_balanced_proj800.npy\", \n",
    "#         upsampled4_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac48d15",
   "metadata": {},
   "source": [
    "\n",
    "Project to a combination of both text and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8da257fe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db28001a214e44d1bfd617194ee3c718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "994",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m800000\u001b[39m)):\n\u001b[1;32m      7\u001b[0m     label \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m     idx_2 \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mall_labels_wiki_and_template\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m)))\n\u001b[1;32m     10\u001b[0m     upsampled5_texts[i] \u001b[38;5;241m=\u001b[39m all_labels_wiki_and_template[label][idx_2]\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     12\u001b[0m     cointoss \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 994"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "upsampled5_images = np.zeros((800000, 1024))\n",
    "upsampled5_texts = np.zeros((800000, 1024))\n",
    "\n",
    "for i in tqdm(range(800000)):\n",
    "    label = random.choice(range(1000))\n",
    "    \n",
    "    idx_2 = random.choice(range(len(all_labels_wiki_and_template[label])))\n",
    "    upsampled5_texts[i] = all_labels_wiki_and_template[label][idx_2].cpu()\n",
    "    \n",
    "    cointoss = random.choice(range(2))\n",
    "    \n",
    "    if cointoss == 0:\n",
    "        idx = random.choice(indices_by_label[label])\n",
    "        upsampled5_images[i] = final_images[idx].cpu()\n",
    "    else:\n",
    "        idx = random.choice(range(len(all_labels_wiki_and_template[label])))\n",
    "        upsampled5_images[i] = all_labels_wiki_and_template[label][idx].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55ae9443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled5_balanced_proj, _, _, _ = lstsq(upsampled5_texts, upsampled5_images)\n",
    "upsampled5_balanced_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d68fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"imagenet_text2img_upsampled5_balanced_proj.npy\", upsampled5_balanced_proj.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2639f93",
   "metadata": {},
   "source": [
    "Using Cupl texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d036a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 454.00 MiB (GPU 0; 10.76 GiB total capacity; 452.52 MiB already allocated; 83.56 MiB free; 454.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m cupl_texts \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/nethome/bdevnani3/flash1/long_tail_lang/results_sklearn/cupl_image_prompts.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m final_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_embedded_images.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m final_texts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclip_embedded_texts.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m final_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_embedded_image_labels.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/torch/serialization.py:1049\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1049\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/torch/serialization.py:1019\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1018\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1019\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39m_UntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/torch/serialization.py:157\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_UntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/torch/_utils.py:78\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_type(indices, values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_UntypedStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 454.00 MiB (GPU 0; 10.76 GiB total capacity; 452.52 MiB already allocated; 83.56 MiB free; 454.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "cupl_texts = json.load(open(\"/nethome/bdevnani3/flash1/long_tail_lang/results_sklearn/cupl_image_prompts.json\"))\n",
    "final_images = torch.load(\"clip_embedded_images.pt\")\n",
    "final_texts = torch.load(\"clip_embedded_texts.pt\")\n",
    "final_labels = torch.load(\"clip_embedded_image_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc523d05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m label_frequencies \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfinal_labels\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m label_frequencies:\n\u001b[1;32m      4\u001b[0m         label_frequencies[label\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_labels' is not defined"
     ]
    }
   ],
   "source": [
    "label_frequencies = {}\n",
    "for label in final_labels:\n",
    "    if label.item() not in label_frequencies:\n",
    "        label_frequencies[label.item()] = 0\n",
    "    label_frequencies[label.item()] += 1\n",
    "\n",
    "indices_by_label = {}\n",
    "\n",
    "for i, label in enumerate(final_labels):\n",
    "    if label.item() not in indices_by_label:\n",
    "        indices_by_label[label.item()] = []\n",
    "    indices_by_label[label.item()].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b030fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2807a3012048ca9cd314fde174c34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cupl_embeds = {}\n",
    "with torch.no_grad():\n",
    "    for key in tqdm(cupl_texts):\n",
    "        txts = clip.tokenize(cupl_texts[key])\n",
    "        txts = txts.cuda()\n",
    "        zeroshot_weights = text_model(txts).float()\n",
    "        zeroshot_weights = zeroshot_weights / zeroshot_weights.norm(\n",
    "            dim=-1, keepdim=True\n",
    "        )\n",
    "        cupl_embeds[key] = zeroshot_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac6750b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1369ee07e748ddb960778ea5189c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "images = np.zeros((800000, 1024))\n",
    "texts = np.zeros((800000, 1024))\n",
    "\n",
    "for i in tqdm(range(800000)):\n",
    "    label = random.choice(range(1000))\n",
    "    label_name = CLASSES[label]\n",
    "    \n",
    "    txt = random.choice(cupl_embeds[label_name])\n",
    "    texts[i] = txt.cpu().detach().numpy()\n",
    "    \n",
    "#     idx = random.choice(indices_by_label[label])\n",
    "#     images[i] = final_images[idx].cpu()\n",
    "    \n",
    "    cointoss = random.choice(range(2))\n",
    "    \n",
    "    if cointoss == 0:\n",
    "        idx = random.choice(indices_by_label[label])\n",
    "        images[i] = final_images[idx].cpu()\n",
    "    else:\n",
    "        txt = random.choice(cupl_embeds[label_name])\n",
    "        images[i] = txt.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96b1f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj, _, _, _ = lstsq(images, texts)\n",
    "proj.shape\n",
    "np.save(\"/nethome/bdevnani3/flash1/long_tail_lang/proj_matrices/cupl_l2_proj_mix.npy\", \n",
    "        proj.astype(float))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7edd5b",
   "metadata": {},
   "source": [
    "Analysis of content of the projection matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled2_balanced_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39509c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = np.linalg.eig(upsampled2_balanced_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23497bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, v = eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in w:\n",
    "    print(round(i,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa377bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(w), max(w), np.std(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37227e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71bcbab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_texts = np.matmul(final_texts.cpu(), upsampled2_balanced_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00d8d99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.5127477473582"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(projected_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "178080fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339.27646"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(final_images.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28306b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339.25623"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(final_texts.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "09098831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.00236D+05    |proj g|=  1.16415D+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.66757D+05    |proj g|=  5.40155D+01\n",
      "\n",
      "At iterate  100    f=  2.66095D+05    |proj g|=  1.68676D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****    100    106      1     0     0   1.687D+00   2.661D+05\n",
      "  F =   266095.48310057109     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/bdevnani3/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 36.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0,verbose=1, n_jobs=-1).fit(projected_texts, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "10796f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894748200196813"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(projected_texts, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d3151631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.00236D+05    |proj g|=  1.16415D+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.31944D+05    |proj g|=  4.53975D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     97    100      1     0     0   3.988D-02   1.319D+05\n",
      "  F =   131928.92824115991     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 49.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7241423959394369"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0,verbose=1, n_jobs=-1).fit(final_texts.cpu(), final_labels)\n",
    "clf.score(projected_texts, final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330f06d",
   "metadata": {},
   "source": [
    "L1 proj matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1a79db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999999, 0.99999999, 0.99999998],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def fit(X, params):\n",
    "    params = params.reshape((3,3))\n",
    "    return np.matmul(X,params)\n",
    "\n",
    "def cost_function(params, X, y):\n",
    "    # L1 \n",
    "    return np.sum(np.abs(y - fit(X, params)))\n",
    "\n",
    "# Sanity \n",
    "images = np.array([[1,1,1], [0,0,0]])\n",
    "text = np.array([[2,2,2], [0,0,0]])\n",
    "x0 = np.random.rand(3,3)\n",
    "\n",
    "output = minimize(cost_function, x0, args=(text, images))\n",
    "\n",
    "proj = fit(text, output.x)\n",
    "proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0598e0",
   "metadata": {},
   "source": [
    "Project to a combination of both text and image - l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54b690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    "\n",
    "# images = np.zeros((400000, 1024))\n",
    "# texts = np.zeros((400000, 1024))\n",
    "\n",
    "# for i in tqdm(range(400000)):\n",
    "#     label = random.choice(range(1000))\n",
    "    \n",
    "#     idx_2 = random.choice(range(len(all_labels_wiki_and_template[label])))\n",
    "#     texts[i] = all_labels_wiki_and_template[label][idx_2].cpu()\n",
    "    \n",
    "#     cointoss = random.choice(range(2))\n",
    "    \n",
    "#     if cointoss == 0:\n",
    "#         idx = random.choice(indices_by_label[label])\n",
    "#         images[i] = final_images[idx].cpu()\n",
    "#     else:\n",
    "#         idx = random.choice(range(len(all_labels_wiki_and_template[label])))\n",
    "#         images[i] = all_labels_wiki_and_template[label][idx].cpu()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd83aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"proj_matrices/l1-var1_images.npy\")\n",
    "\n",
    "texts = np.load(\"proj_matrices/l1-var1_texts.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73633e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def fit(X, params):\n",
    "    params = params.reshape((1024,1024))\n",
    "    return np.matmul(X,params)\n",
    "\n",
    "def cost_function(params, X, y):\n",
    "    # L1 \n",
    "    return np.sum(np.abs(y - fit(X, params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8b1723e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/bdevnani3/flash1/miniconda3/envs/ltr/lib/python3.9/importlib/__init__.py:169: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.00 TiB for an array with shape (1048576, 1048576) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(np)\n\u001b[1;32m      5\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1024\u001b[39m,\u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m l1_proj_1 \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m      9\u001b[0m l1_proj_1\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_minimize.py:685\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    683\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_powell(fun, x0, args, callback, bounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 685\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_cg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    687\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_optimize.py:1609\u001b[0m, in \u001b[0;36m_minimize_cg\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1607\u001b[0m     maxiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x0) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m-> 1609\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1612\u001b[0m f \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m   1613\u001b[0m myfprime \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_optimize.py:263\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:177\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[1;32m    174\u001b[0m                                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad_impl \u001b[38;5;241m=\u001b[39m update_grad\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Hessian Evaluation\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(hess):\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:570\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    568\u001b[0m n \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m    569\u001b[0m J_transposed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n, m))\n\u001b[0;32m--> 570\u001b[0m h_vecs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(h\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2-point\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdiag\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/flash1/miniconda3/envs/ltr/lib/python3.9/site-packages/numpy/lib/twodim_base.py:293\u001b[0m, in \u001b[0;36mdiag\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mabs\u001b[39m(k)\n\u001b[0;32m--> 293\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m         i \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 8.00 TiB for an array with shape (1048576, 1048576) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "importlib.reload(np)\n",
    "\n",
    "x0 = np.random.rand(1024,1024)\n",
    "\n",
    "output = minimize(cost_function, x0, args=(texts, images), method=\"CG\")\n",
    "l1_proj_1 = output.x\n",
    "l1_proj_1.shape\n",
    "\n",
    "np.save(\"proj_matrices/l1-var1.npy\", \n",
    "        l1_proj_1.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8742c6",
   "metadata": {},
   "source": [
    "Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caa906da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.92599493, 2.57051579, 2.60768697],\n",
       "       [0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "def fit(X, params):\n",
    "    params = params.reshape((3,3))\n",
    "    return np.matmul(X,params)\n",
    "\n",
    "def cost_function(params, X, y):\n",
    "    # cosine\n",
    "    return np.sum(1- sklearn.metrics.pairwise.cosine_similarity(y, x).diagonal())\n",
    "\n",
    "\n",
    "# Sanity \n",
    "images = np.array([[1,1,1], [0,0,0]])\n",
    "text = np.array([[2,2,2], [0,0,0]])\n",
    "x0 = np.random.rand(3,3)\n",
    "\n",
    "output = minimize(cost_function, x0, args=(text, images))\n",
    "\n",
    "proj = fit(text, output.x)\n",
    "proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1dc7ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1291fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
