{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30fa5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import CLASSES, GENERIC_PROMPT_COLLECTIONS\n",
    "import torch.nn as nn\n",
    "from clip import clip\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "# Initialize CLIP models \n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, clip_model):\n",
    "        super().__init__()\n",
    "        self.transformer = clip_model.transformer\n",
    "        self.positional_embedding = clip_model.positional_embedding\n",
    "        self.ln_final = clip_model.ln_final\n",
    "        self.text_projection = clip_model.text_projection\n",
    "        self.dtype = clip_model.dtype\n",
    "        self.token_embedding = clip_model.token_embedding\n",
    "\n",
    "    def forward(self, text):\n",
    "        x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "        x = x + self.positional_embedding.type(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection\n",
    "\n",
    "        return x\n",
    "\n",
    "def load_clip_to_cpu(visual_backbone):\n",
    "    backbone_name = visual_backbone\n",
    "    url = clip._MODELS[backbone_name]\n",
    "    model_path = clip._download(url, os.path.expanduser(\"~/.cache/clip\"))\n",
    "\n",
    "    try:\n",
    "        # loading JIT archive\n",
    "        model = torch.jit.load(model_path, map_location=\"cpu\").eval()\n",
    "        state_dict = None\n",
    "\n",
    "    except RuntimeError:\n",
    "        state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "\n",
    "    model = clip.build_model(state_dict or model.state_dict())\n",
    "\n",
    "    return model\n",
    "\n",
    "clip_model = load_clip_to_cpu(\"RN50\")\n",
    "\n",
    "visual_model = torch.nn.DataParallel(clip_model.visual).cuda()\n",
    "\n",
    "text_model = TextEncoder(clip_model)\n",
    "text_model = torch.nn.DataParallel(text_model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4b4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import sys  \n",
    "sys.path.insert(0, '/nethome/bdevnani3/flash1/long_tail_lang/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from clip import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645b981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('RN50', device)\n",
    "\n",
    "# Download the dataset\n",
    "# cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "# # Prepare the inputs\n",
    "# image, class_id = cifar100[3637]\n",
    "# image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "# text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# # Calculate features\n",
    "# with torch.no_grad():\n",
    "#     image_features = model.encode_image(image_input)\n",
    "#     text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# # Pick the top 5 most similar labels for the image\n",
    "# image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "# text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b05a1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d3054e93b54cdcb52454fac5dec5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "all_labels_text = {}\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for label in tqdm(range(1000)):\n",
    "        all_labels_text[label] = []\n",
    "\n",
    "        templates = np.array(GENERIC_PROMPT_COLLECTIONS[\"ImageNet\"])\n",
    "        c = np.array(CLASSES)[label]\n",
    "            \n",
    "        texts = clip.tokenize([template.format(c) for template in templates]) \n",
    "        texts = texts.cuda()\n",
    "        zeroshot_weights = model.encode_text(texts).float()\n",
    "        zeroshot_weights = zeroshot_weights / zeroshot_weights.norm(\n",
    "            dim=-1, keepdim=True\n",
    "        )\n",
    "        all_labels_text[label].append(zeroshot_weights)\n",
    "        data.append(zeroshot_weights)\n",
    "        for i in range(len(templates)):\n",
    "            labels.append(label)\n",
    "        \n",
    "data = torch.cat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59241ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /nethome/bdevnani3/flash1/long_tail_lang/data/ImageNet_LT/ImageNet_LT_test.txt\n",
      "Use data transformation: Compose(\n",
      "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      ")\n",
      "***********************DATASET: test random_prompts\n",
      "test 50000\n",
      "No sampler.\n",
      "Shuffle is True.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ae96549b0642dcabbd6814d5ed5e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data_loader import dataloaders as dataloader\n",
    "d = dataloader.load_data(\n",
    "    data_root=\"../datasets/ImageNet/\",\n",
    "    dataset=\"ImageNet_LT\",\n",
    "    phase=\"test\",\n",
    "    batch_size=128,\n",
    "#     batch_size=1,\n",
    "    sampler_dic=None,\n",
    "    num_workers=12,\n",
    "    type=\"random_prompts\",\n",
    "    prompt_set=\"ImageNet\",\n",
    ")\n",
    "data_test = d[0]\n",
    "\n",
    "from classes import CLASSES, CUSTOM_TEMPLATES, GENERIC_PROMPT_COLLECTIONS\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "test_images, test_texts = [], []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for im, label, _, path in tqdm(data_test):\n",
    "        x = visual_model(im.half()).float()\n",
    "        x = x / x.norm(dim=-1, keepdim=True)\n",
    "        test_images.append(x)\n",
    "        test_labels.append(label)\n",
    "        \n",
    "test_images = torch.cat(test_images, dim=0)\n",
    "test_labels = torch.cat(test_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1b8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_images = torch.load(\"../clip_embedded_images.pt\")\n",
    "lt_images_labels = torch.load(\"../clip_embedded_image_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac8a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbe0b1786ef4a92b2c90d68005a5be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 19250]) torch.Size([19250])\n",
      "torch.Size([1024, 23450]) torch.Size([23450])\n",
      "torch.Size([1024, 7300]) torch.Size([7300])\n"
     ]
    }
   ],
   "source": [
    "freqs = {}\n",
    "for label in lt_images_labels:\n",
    "    label = int(label.item())\n",
    "    if label not in freqs:\n",
    "        freqs[label] = 0\n",
    "    freqs[label] +=1\n",
    "    \n",
    "label_cats = {\"many\":[], \"med\":[], \"few\":[]}\n",
    "for label in set(lt_images_labels):\n",
    "    label = label.item()\n",
    "    if freqs[label] > 100:\n",
    "        label_cats[\"many\"].append(label)\n",
    "    elif freqs[label] > 20:\n",
    "        label_cats[\"med\"].append(label)\n",
    "    else:\n",
    "        label_cats[\"few\"].append(label)\n",
    "import json\n",
    "# json.dump(freqs, open(\"/nethome/bdevnani3/flash1/long_tail_lang/embedding_datasets/class_frequencies.json\", \"w\"))\n",
    "# json.dump(label_cats, open(\"/nethome/bdevnani3/flash1/long_tail_lang/embedding_datasets/label_classification.json\", \"w\"))\n",
    "\n",
    "many_test_images, med_test_images, few_test_images = [], [], []\n",
    "many_test_labels, med_test_labels, few_test_labels = [], [], []\n",
    "\n",
    "for i,l in tqdm(zip(test_images, test_labels)):\n",
    "    \n",
    "    if l.item() in label_cats[\"many\"]:\n",
    "        many_test_images.append(i)\n",
    "        many_test_labels.append(l.item())\n",
    "    elif l.item() in label_cats[\"med\"]:\n",
    "        med_test_images.append(i)\n",
    "        med_test_labels.append(l.item())\n",
    "    elif l.item() in label_cats[\"few\"]:\n",
    "        few_test_images.append(i)\n",
    "        few_test_labels.append(l.item())\n",
    "        \n",
    "many_test_images = torch.stack(many_test_images,dim=1)\n",
    "med_test_images = torch.stack(med_test_images,dim=1)\n",
    "few_test_images = torch.stack(few_test_images,dim=1)\n",
    "many_test_labels = torch.tensor(many_test_labels)\n",
    "med_test_labels = torch.tensor(med_test_labels)\n",
    "few_test_labels = torch.tensor(few_test_labels)\n",
    "\n",
    "print(many_test_images.shape, many_test_labels.shape)\n",
    "print(med_test_images.shape, med_test_labels.shape)\n",
    "print(few_test_images.shape, few_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f678eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c9794",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.66436D+05    |proj g|=  3.41085D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(data.cpu(), labels)\n",
    "print(clf.score(data.cpu(), labels))\n",
    "print(clf.score(lt_images.cpu(), lt_images_labels.cpu()))\n",
    "print(clf.score(test_images.cpu(), test_labels.cpu()))\n",
    "\n",
    "print(\"Many:\", clf.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = np.load(\"../imagenet_text2img_upsampled2_balanced_proj200.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93ffa9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.66436D+05    |proj g|=  1.98860D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.86660D+05    |proj g|=  2.55931D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     67     76      1     0     0   4.672D-02   2.867D+05\n",
      "  F =   286660.26624696294     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997719512195122\n",
      "0.5206049410424184\n",
      "0.50536\n",
      "Many: 0.5295064935064935\n",
      "Med: 0.49415778251599146\n",
      "Few: 0.4776712328767123\n",
      "All: 0.50536\n"
     ]
    }
   ],
   "source": [
    "data_proj = np.matmul(data.cpu(), proj)\n",
    "clf_proj = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(data_proj.cpu(), labels)\n",
    "print(clf_proj.score(data_proj.cpu(), labels))\n",
    "print(clf_proj.score(lt_images.cpu(), lt_images_labels.cpu()))\n",
    "print(clf_proj.score(test_images.cpu(), test_labels.cpu()))\n",
    "\n",
    "print(\"Many:\", clf_proj.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf_proj.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf_proj.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf_proj.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "768f3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj400 = np.load(\"../imagenet_text2img_upsampled2_balanced_proj400.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f92c164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.66436D+05    |proj g|=  1.93401D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.87502D+05    |proj g|=  8.18398D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     63     74      1     0     0   5.916D-02   2.875D+05\n",
      "  F =   287501.73315015755     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many: 0.5305454545454545\n",
      "Med: 0.4933049040511727\n",
      "Few: 0.4706849315068493\n",
      "All: 0.50434\n"
     ]
    }
   ],
   "source": [
    "data_proj400 = np.matmul(data.cpu(), proj400)\n",
    "clf_proj400 = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(data_proj400.cpu(), labels)\n",
    "clf_proj400.score(data_proj.cpu(), labels)\n",
    "clf_proj400.score(lt_images.cpu(), lt_images_labels)\n",
    "\n",
    "print(\"Many:\", clf_proj400.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf_proj400.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf_proj400.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf_proj400.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb3dab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.66436D+05    |proj g|=  1.33026D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.99440D+05    |proj g|=  1.56454D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     55     67      1     0     0   5.021D-02   2.994D+05\n",
      "  F =   299440.38180914812     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many: 0.5495064935064935\n",
      "Med: 0.5198294243070363\n",
      "Few: 0.5089041095890411\n",
      "All: 0.52966\n"
     ]
    }
   ],
   "source": [
    "projmix = np.load(\"../imagenet_text2img_upsampled5_balanced_proj.npy\")\n",
    "\n",
    "data_projmix = np.matmul(data.cpu(), projmix)\n",
    "clf_projmix = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(data_projmix.cpu(), labels)\n",
    "# clf_projmix.score(clf_projmix.cpu(), labels)\n",
    "# clf_projmix.score(lt_images.cpu(), lt_images_labels)\n",
    "\n",
    "print(\"Many:\", clf_projmix.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf_projmix.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf_projmix.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf_projmix.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23433a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.66436D+05    |proj g|=  1.79337D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  3.13100D+05    |proj g|=  7.53471D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     62     73      1     0     0   2.077D-01   3.131D+05\n",
      "  F =   313099.83803925075     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many: 0.5076883116883116\n",
      "Med: 0.47961620469083155\n",
      "Few: 0.47054794520547943\n",
      "All: 0.4891\n"
     ]
    }
   ],
   "source": [
    "projmix = np.load(\"../imagenet_text2img_upsampled4_balanced_proj.npy\")\n",
    "\n",
    "data_projmix = np.matmul(data.cpu(), projmix)\n",
    "clf_projmix = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(data_projmix.cpu(), labels)\n",
    "# clf_projmix.score(clf_projmix.cpu(), labels)\n",
    "# clf_projmix.score(lt_images.cpu(), lt_images_labels)\n",
    "\n",
    "print(\"Many:\", clf_projmix.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf_projmix.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf_projmix.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf_projmix.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f69b80c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.66436D+05    |proj g|=  1.75366D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  3.13635D+05    |proj g|=  1.02537D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     63     69      1     0     0   1.526D-02   3.136D+05\n",
      "  F =   313634.96176935395     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many: 0.507012987012987\n",
      "Med: 0.48136460554371\n",
      "Few: 0.4724657534246575\n",
      "All: 0.48994\n"
     ]
    }
   ],
   "source": [
    "projmix = np.load(\"../imagenet_text2img_upsampled4_balanced_proj800.npy\")\n",
    "\n",
    "data_projmix = np.matmul(data.cpu(), projmix)\n",
    "clf_projmix = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(data_projmix.cpu(), labels)\n",
    "# clf_projmix.score(clf_projmix.cpu(), labels)\n",
    "# clf_projmix.score(lt_images.cpu(), lt_images_labels)\n",
    "\n",
    "print(\"Many:\", clf_projmix.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf_projmix.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf_projmix.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf_projmix.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaaa12df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cupl_prompt_embeds= torch.load(\"../embedding_datasets/clip/Balanced_culp_text_train_ImageNet/text_embeddings.pt\")\n",
    "cupl_prompt_labels= torch.load(\"../embedding_datasets/clip/Balanced_culp_text_train_ImageNet/labels.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e49f570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.45388D+05    |proj g|=  2.01144D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.19202D+05    |proj g|=  1.94563D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****     50     58      1     0     0   1.946D-02   1.192D+05\n",
      "  F =   119201.88999533509     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 54.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many: 0.5105974025974026\n",
      "Med: 0.4977398720682303\n",
      "Few: 0.4643835616438356\n",
      "All: 0.49782\n"
     ]
    }
   ],
   "source": [
    "projmix = np.load(\"../proj_matrices/cupl_l2_proj.npy\")\n",
    "\n",
    "\n",
    "clf_projmix = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(cupl_prompt_embeds.cpu(), cupl_prompt_labels)\n",
    "# clf_projmix.score(clf_projmix.cpu(), labels)\n",
    "# clf_projmix.score(lt_images.cpu(), lt_images_labels)\n",
    "\n",
    "print(\"Many:\", clf_projmix.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf_projmix.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf_projmix.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf_projmix.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =      1025000     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.45388D+05    |proj g|=  1.59717D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "projmix = np.load(\"../proj_matrices/cupl_l2_proj_mix.npy\")\n",
    "data_projmix = np.matmul(cupl_prompt_embeds.cpu(), projmix)\n",
    "\n",
    "clf_projmix = LogisticRegression(random_state=0, verbose=1, n_jobs=-1).fit(data_projmix, cupl_prompt_labels)\n",
    "# clf_projmix.score(clf_projmix.cpu(), labels)\n",
    "# clf_projmix.score(lt_images.cpu(), lt_images_labels)\n",
    "\n",
    "print(\"Many:\", clf_projmix.score(many_test_images.T.cpu(), many_test_labels.cpu()))\n",
    "print(\"Med:\", clf_projmix.score(med_test_images.T.cpu(), med_test_labels.cpu()))\n",
    "print(\"Few:\", clf_projmix.score(few_test_images.T.cpu(), few_test_labels.cpu()))\n",
    "print(\"All:\", clf_projmix.score(test_images.cpu(), test_labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56810e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d250310ed4aec6ba3d073b23ed5df4ee2207733ce20a46dc5c795db6f9c9b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
